{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YErqpfH9jVI"
      },
      "source": [
        "# RAG ËØÑ‰º∞\n",
        "_‰ΩúËÄÖ [Aymeric Roucher](https://huggingface.co/m-ric)_\n",
        "\n",
        "Êú¨ notebook ÊºîÁ§∫‰∫ÜÂ¶Ç‰ΩïËØÑ‰º∞‰Ω†ÁöÑ RAGÔºàRetrieval Augmented GenerationÔºâÔºåÈÄöËøáÊûÑÂª∫‰∏Ä‰∏™ÂêàÊàêËØÑ‰º∞Êï∞ÊçÆÈõÜÂπ∂‰ΩøÁî® LLM-as-a-judge Êù•ËÆ°ÁÆó‰Ω†Á≥ªÁªüÁöÑÂáÜÁ°ÆÊÄß„ÄÇ\n",
        "\n",
        "ÂØπ‰∫é RAG Á≥ªÁªüÁöÑ‰ªãÁªçÔºå‰Ω†ÂèØ‰ª•Êü•Áúã[Ëøô‰∏™ÊäÄÊúØÊåáÂçó](rag_zephyr_langchain)!\n",
        "\n",
        "RAG Á≥ªÁªüÂæàÂ§çÊùÇ: ËøôÈáåÊúâ‰∏Ä‰∏™ RAG ÊµÅÁ®ãÂõæÔºåÊàë‰ª¨Áî®ËìùËâ≤Ê†áÊ≥®‰∫ÜÁ≥ªÁªüÂ¢ûÂº∫ÁöÑÊâÄÊúâÂèØËÉΩÊÄßÔºö\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface/cookbook-images/resolve/main/RAG_workflow.png\" height=\"700\">\n",
        "\n",
        "ÂÆûÊñΩ‰∏äËø∞‰ªª‰ΩïÊîπËøõÈÉΩÂèØËÉΩ‰ºöÂ∏¶Êù•Â∑®Â§ßÁöÑÊÄßËÉΩÊèêÂçáÔºõ‰ΩÜÂ¶ÇÊûúÊó†Ê≥ïÁõëÊéßÂØπÁ≥ªÁªüÊÄßËÉΩÁöÑÂΩ±ÂìçÔºåÈÇ£‰πàËøõË°å‰ªª‰ΩïÊõ¥ÊîπÈÉΩÊòØÊó†Áî®ÁöÑÔºÅËÆ©Êàë‰ª¨ÁúãÁúãÂ¶Ç‰ΩïËØÑ‰º∞Êàë‰ª¨ÁöÑ RAG Á≥ªÁªü„ÄÇ\n",
        "\n",
        "### ËØÑ‰º∞RAGÊÄßËÉΩ\n",
        "\n",
        "Áî±‰∫éÊúâÂ¶ÇÊ≠§Â§öÁöÑÈÉ®ÂàÜÈúÄË¶ÅË∞ÉÊï¥ÔºåËøô‰∫õÈÉ®ÂàÜÂØπÊÄßËÉΩÊúâÂæàÂ§ßÂΩ±ÂìçÔºåÂõ†Ê≠§ÂØπ RAG Á≥ªÁªüËøõË°åÂü∫ÂáÜÊµãËØïÊòØËá≥ÂÖ≥ÈáçË¶ÅÁöÑ„ÄÇ\n",
        "\n",
        "ÂØπ‰∫éÊàë‰ª¨ÁöÑËØÑ‰º∞ÊµÅÊ∞¥Á∫øÔºåÊàë‰ª¨Â∞ÜÈúÄË¶ÅÔºö\n",
        "1. ‰∏Ä‰∏™Â∏¶ÊúâÈóÆÈ¢ò-Á≠îÊ°àÂØπÁöÑËØÑ‰º∞Êï∞ÊçÆÈõÜÔºàQA ÂØπÔºâ\n",
        "2. ‰∏Ä‰∏™ËØÑ‰º∞Âô®ÔºåÁî®‰∫éËÆ°ÁÆóÊàë‰ª¨ÁöÑÁ≥ªÁªüÂú®‰∏äÈù¢ÁöÑËØÑ‰º∞Êï∞ÊçÆÈõÜ‰∏äÁöÑÂáÜÁ°ÆÊÄß„ÄÇ\n",
        "\n",
        "‚û°Ô∏è ÁªìÊûúÂèëÁé∞ÔºåÊàë‰ª¨ÂèØ‰ª•Âú®Êï¥‰∏™ËøáÁ®ã‰∏≠‰ΩøÁî® LLMs Êù•Â∏ÆÂä©ÔºÅ\n",
        "1. ËØÑ‰º∞Êï∞ÊçÆÈõÜÂ∞ÜÁî± LLM ü§ñ ÂêàÊàêÁîüÊàêÔºåÂπ∂‰∏îÈóÆÈ¢òÂ∞ÜÁî±ÂÖ∂‰ªñ LLM ü§ñ ËøáÊª§Êéâ\n",
        "2. ÁÑ∂ÂêéÔºå[LLM-as-a-judge](https://huggingface.co/papers/2306.05685) Êô∫ËÉΩ‰Ωì ü§ñ Â∞ÜÂú®Ëøô‰∏™ÂêàÊàêÊï∞ÊçÆÈõÜ‰∏äÊâßË°åËØÑ‰º∞„ÄÇ\n",
        "\n",
        "\n",
        "__ËÆ©Êàë‰ª¨Ê∑±ÂÖ•ÊåñÊéòÂπ∂ÂºÄÂßãÊûÑÂª∫Êàë‰ª¨ÁöÑËØÑ‰º∞ÊµÅÊ∞¥Á∫øÔºÅ__ È¶ñÂÖàÔºåÂÆâË£ÖÊâÄÈúÄÁöÑÊ®°Âûã‰æùËµñÈ°π„ÄÇ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bCKBvOcp9jVK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "201d8892-2baf-49b1-c36b-6d5832223bbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/2.5 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m303.3/303.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m332.9/332.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m310.5/310.5 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q torch transformers transformers langchain sentence-transformers tqdm openpyxl openai pandas datasets langchain-community ragatouille"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "k_lJFbYm9jVL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "fa117c73-635f-4343-b9aa-53c524c4b541"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'imp'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3577020505.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'reload_ext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2416\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2418\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2419\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mreload_ext\u001b[0;34m(self, module_str)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magics/extension.py\u001b[0m in \u001b[0;36mreload_ext\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodule_str\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mUsageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Missing module name.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/extensions.py\u001b[0m in \u001b[0;36mreload_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_load_ipython_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/extensions.py\u001b[0m in \u001b[0;36mload_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodule_str\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mprepended_to_syspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                         print((\"Loading extensions from {dir} is deprecated. \"\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/extensions/autoreload.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimportlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msource_from_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;31m#------------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imp'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oIlNZ1Mn9jVL"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "import pandas as pd\n",
        "from typing import Optional, List, Tuple\n",
        "import json\n",
        "import datasets\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "32f463ea32c84e7d9bc1bb76c170f0a9",
            "715783304b4647ecae49725bea5777f2",
            "9648a6b9b118409fa5c99419eb2809dc",
            "7744ff3befb347c6a0925eeb29ae534c",
            "cdf11561f3da44ea8ae56f1ceeafca00",
            "23fbd90a3e9140e9873a9b9f3d44960c",
            "ae7726e4727e4d6298451aa4559ede5d",
            "6c53cd547bff4bbc98cc55cf7283edc6",
            "8fddc047c10940ce9d48b13f84001f7c",
            "a885884e492540ec943805bf3f689e8c",
            "8c1bbd364f7540cfa5a9dbc6c7e1df5e",
            "66c16e71676745a8badd398ab053889c",
            "f14ecb1c41fc413d9897e4617ec580ea",
            "d25a4a1279c94979a2fcbab3456ca82c",
            "b42efb6c58644739850d73005388ed61",
            "0e73bf32b43d4f8cba46e5db5e28f798",
            "2fdbc55ec3c14f23ab0133107fb90cd9",
            "c7ca55f298eb4414ad50198f09208770",
            "0cf32a3f9ed54041862cec3164ded745",
            "81facfe068164284ac22658e79103844"
          ]
        },
        "id": "INJ1MLzkJDaP",
        "outputId": "327aace4-6925-4dbf-d8b4-9d2a1fe617ba"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32f463ea32c84e7d9bc1bb76c170f0a9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeW8P62J9jVM"
      },
      "source": [
        "### Âä†ËΩΩ‰Ω†ÁöÑÁü•ËØÜÂü∫Á°Ä"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YRbm5tNF9jVM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217,
          "referenced_widgets": [
            "7630c7d2a6df48858b55f6817555b6ab",
            "c4ddab2a133d494f9adb665380c38a84",
            "e1d521f629db424aafc6b0bf3d319182",
            "701fd33d8bf742b7a36c65faaac7712d",
            "930f94e2a23b4b5ca85a1f06ceb7be91",
            "0114ab46748e4714b974d2c685ff2970",
            "49d9c8f88fe34322b2033950263b6aca",
            "45122afe4e2240dfa0c76544b9e47444",
            "e9d884068cb74b86939e7f42ae23cf48",
            "71ea33516c4c46f3af4e213c3bdb12ab",
            "f1e5616300344e72b5708d0ae8ab737d",
            "074a8622d4e74b038b4a238a367d2d73",
            "fa273886c3f14a43a30b9e066a966e82",
            "0a2ade07714b45bcac34ddf05db4b5a8",
            "3351d460f3654eefa5ec55f7cd8deb12",
            "d7bdbc4956294556b795130b1ccf02fb",
            "8f826c0c5c1a4b56be93d92ba19142f9",
            "0feb654359ee42a5a2eb0fcea9c8e296",
            "1773c0e8d24b436baf47d408ae5772bb",
            "6e34370413bc46ac84c875666b4b4f64",
            "8c20b85756d740e1963beb54eaa438df",
            "cd83bc04017141289ae42aac004971b7",
            "c68c2360cc5e4eed9558cddf3cadba83",
            "71fd308ef03949aebbde84630ffe30fc",
            "1d325c3a97664d65b6150be2c15ff42b",
            "41ca68cc80f147fcb11f59d599c67c03",
            "7993e139a0f34b01b7ebac0a495e1f97",
            "1b95b460242a45a985de2f88ccb82b21",
            "f43535d75d3f440ba2221b3ef91d1a6f",
            "9b526892b309478e94309f737961b53c",
            "8ba6812e6fda455087d14dd3266bb69e",
            "99deb331d21748bb9ea0960213356528",
            "eaa6853bf2ea4b78a2ae9d12647b1909"
          ]
        },
        "outputId": "37686c43-59fa-454a-9242-f195009f222f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/21.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7630c7d2a6df48858b55f6817555b6ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "huggingface_doc.csv:   0%|          | 0.00/22.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "074a8622d4e74b038b4a238a367d2d73"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/2647 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c68c2360cc5e4eed9558cddf3cadba83"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "ds = datasets.load_dataset(\"m-ric/huggingface_doc\", split=\"train\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wy9CKj0M9jVM"
      },
      "source": [
        "# 1. ‰∏∫ËØÑ‰º∞ÊûÑÂª∫ÂêàÊàêÊï∞ÊçÆÈõÜ\n",
        "\n",
        "Êàë‰ª¨È¶ñÂÖàÊûÑÂª∫‰∏Ä‰∏™ÈóÆÈ¢òÂíåÁõ∏ÂÖ≥‰∏ä‰∏ãÊñáÁöÑÁªºÂêàÊï∞ÊçÆÈõÜ„ÄÇÊñπÊ≥ïÊòØÂÖà‰ªéÊàë‰ª¨ÁöÑÁü•ËØÜÂ∫ì‰∏≠Ëé∑ÂèñÂÖÉÁ¥†ÔºåÂπ∂ËÆ© LLM Ê†πÊçÆËøô‰∫õÊñáÊ°£ÁîüÊàêÈóÆÈ¢ò„ÄÇ\n",
        "\n",
        "ÁÑ∂ÂêéÔºåÊàë‰ª¨ËÆæÁΩÆÂÖ∂‰ªñ LLM Êô∫ËÉΩ‰Ωì‰Ωú‰∏∫ÁîüÊàêÈóÆÁ≠îÂØπÁöÑË¥®ÁΩÆËøáÊª§Âô®ÔºöÊØè‰∏™Êô∫ËÉΩ‰ΩìÂ∞Ü‰Ωú‰∏∫‰∏Ä‰∏™ÁâπÂÆöÁº∫Èô∑ÁöÑËøáÊª§Âô®„ÄÇ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkoEgiDg9jVM"
      },
      "source": [
        "### 1.1. ÂáÜÂ§áÊ∫êÊï∞ÊçÆÊñáÊ°£"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3gTOlRKO9jVM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "9b7c62a723914de9a28f759ad3e868b5",
            "fd6e131ae5c440c1bb153c7ae1ae6371",
            "6cc4b010047b4258ba6d152da6d7c76b",
            "20f32624d169465186273bbb2edb7dd4",
            "87ed8949d45b40dbb7fadb4fe9e64952",
            "4ed7c849df634e80a42ccbe4f09fa1a0",
            "9eefca8c10b140a6a04c0cc8cc6ec712",
            "3ce7628b5bb54a9b9c15ba4f96336307",
            "44308eae38244f00ab63b43c9d226286",
            "0e9c358c2ea14089bd0418fe530d0c01",
            "f0d07659f56c40c6b71f64222cce9779"
          ]
        },
        "outputId": "a2749c37-58eb-4708-94f3-d59170feaf11"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2647 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b7c62a723914de9a28f759ad3e868b5"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.docstore.document import Document as LangchainDocument\n",
        "\n",
        "langchain_docs = [\n",
        "    LangchainDocument(page_content=doc[\"text\"], metadata={\"source\": doc[\"source\"]})\n",
        "    for doc in tqdm(ds)\n",
        "]\n",
        "\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=2000,\n",
        "    chunk_overlap=200,\n",
        "    add_start_index=True,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
        ")\n",
        "\n",
        "docs_processed = []\n",
        "for doc in langchain_docs:\n",
        "    docs_processed += text_splitter.split_documents([doc])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjrNhcCh9jVN"
      },
      "source": [
        "### 1.2. ‰∏∫ÈóÆÈ¢òÁîüÊàêËÆæÁΩÆÊô∫ËÉΩ‰Ωì\n",
        "\n",
        "Êàë‰ª¨ÈááÁî® [Mixtral](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1) ‰Ωú‰∏∫ÈóÆÁ≠îÂØπÁöÑÁîüÊàêÔºåÂõ†‰∏∫‰ªñÂú®ÂêÑ‰∏™ÊéíË°åÊ¶ú‰∏äË°®Áé∞ÊûÅ‰Ω≥ÔºåÊØîÂ¶Ç [Chatbot Arena](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard)„ÄÇ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GoRySj3Q9jVN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "fafb87e6-9bb9-42bc-bf0d-7f343d4f700e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "InferenceClient.text_generation() got an unexpected keyword argument 'json'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-626942010.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mcall_llm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"This is a test context\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-626942010.py\u001b[0m in \u001b[0;36mcall_llm\u001b[0;34m(inference_client, prompt)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcall_llm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minference_client\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mInferenceClient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     response = inference_client.text_generation(\n\u001b[0m\u001b[1;32m     14\u001b[0m         json={\n\u001b[1;32m     15\u001b[0m             \u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: InferenceClient.text_generation() got an unexpected keyword argument 'json'"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import InferenceClient\n",
        "\n",
        "\n",
        "repo_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
        "\n",
        "llm_client = InferenceClient(\n",
        "    model=repo_id,\n",
        "    timeout=120,\n",
        ")\n",
        "\n",
        "\n",
        "def call_llm(inference_client: InferenceClient, prompt: str):\n",
        "    response = inference_client.text_generation(\n",
        "        json={\n",
        "            \"inputs\": prompt,\n",
        "            \"parameters\": {\"max_new_tokens\": 1000},\n",
        "            \"task\": \"text-generation\",\n",
        "        },\n",
        "    )\n",
        "    return json.loads(response.decode())[0][\"generated_text\"]\n",
        "\n",
        "\n",
        "call_llm(llm_client, \"This is a test context\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIM_DJRo9jVN"
      },
      "outputs": [],
      "source": [
        "QA_generation_prompt = \"\"\"\n",
        "Your task is to write a factoid question and an answer given a context.\n",
        "Your factoid question should be answerable with a specific, concise piece of factual information from the context.\n",
        "Your factoid question should be formulated in the same style as questions users could ask in a search engine.\n",
        "This means that your factoid question MUST NOT mention something like \"according to the passage\" or \"context\".\n",
        "\n",
        "Provide your answer as follows:\n",
        "\n",
        "Output:::\n",
        "Factoid question: (your factoid question)\n",
        "Answer: (your answer to the factoid question)\n",
        "\n",
        "Now here is the context.\n",
        "\n",
        "Context: {context}\\n\n",
        "Output:::\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVFc-lVy9jVN"
      },
      "source": [
        "Áé∞Âú®ËÆ©Êàë‰ª¨ÁîüÊàêÊàë‰ª¨ÁöÑÈóÆÁ≠îÂØπ„ÄÇ\n",
        "\n",
        "ÂØπ‰∫éËøô‰∏™‰æãÂ≠êÔºåÊàë‰ª¨Âè™ÁîüÊàê 10 ‰∏™ÈóÆÁ≠îÂØπÔºåÂπ∂‰ªé Hub Âä†ËΩΩÂÖ∂‰ΩôÁöÑ„ÄÇ\n",
        "\n",
        "‰ΩÜÊòØÂØπ‰∫é‰Ω†ÁöÑÁâπÂÆöÁü•ËØÜÂ∫ìÔºåËÄÉËôëÂà∞‰Ω†ÊÉ≥Ë¶ÅËé∑ÂæóËá≥Â∞ëÁ∫¶ 100 ‰∏™ÊµãËØïÊ†∑Êú¨ÔºåÂπ∂‰∏îËÄÉËôëÂà∞Êàë‰ª¨Á®çÂêé‰ºöÁî®Êàë‰ª¨ÁöÑÊâπÂà§Êô∫ËÉΩ‰ΩìËøáÊª§ÊéâÂ§ßÁ∫¶‰∏ÄÂçäÁöÑÊ†∑Êú¨Ôºå‰Ω†Â∫îËØ•ÁîüÊàêÊõ¥Â§öÁöÑÊ†∑Êú¨ÔºåË∂ÖËøá 200 ‰∏™„ÄÇ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fteqDDD9jVN"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "N_GENERATIONS = 10  # We intentionally generate only 10 QA couples here for cost and time considerations\n",
        "\n",
        "print(f\"Generating {N_GENERATIONS} QA couples...\")\n",
        "\n",
        "outputs = []\n",
        "for sampled_context in tqdm(random.sample(docs_processed, N_GENERATIONS)):\n",
        "    # Generate QA couple\n",
        "    output_QA_couple = call_llm(\n",
        "        llm_client, QA_generation_prompt.format(context=sampled_context.page_content)\n",
        "    )\n",
        "    try:\n",
        "        question = output_QA_couple.split(\"Factoid question: \")[-1].split(\"Answer: \")[0]\n",
        "        answer = output_QA_couple.split(\"Answer: \")[-1]\n",
        "        assert len(answer) < 300, \"Answer is too long\"\n",
        "        outputs.append(\n",
        "            {\n",
        "                \"context\": sampled_context.page_content,\n",
        "                \"question\": question,\n",
        "                \"answer\": answer,\n",
        "                \"source_doc\": sampled_context.metadata[\"source\"],\n",
        "            }\n",
        "        )\n",
        "    except:\n",
        "        continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUlOUDv59jVN",
        "outputId": "c9634fdb-2a7f-43a6-c4eb-e60b166b8238"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>source_doc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\\nthe License. You may obtain a copy of the License at\\n\\nhttp://www.apache.org/licenses/LICENSE-2.0\\n\\nUnless required by applicable law or agreed to in writing, software distributed under the License is distributed on\\nan \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\\nspecific language governing permissions and limitations under the License.\\n--&gt;\\n\\n# Schedulers\\n\\nü§ó Diffusers provides many scheduler functions for the diffusion process. A scheduler takes a model's output (the sample which the diffusion process is iterating on) and a timestep to return a denoised sample. The timestep is important because it dictates where in the diffusion process the step is; data is generated by iterating forward *n* timesteps and inference occurs by propagating backward through the timesteps. Based on the timestep, a scheduler may be *discrete* in which case the timestep is an `int` or *continuous* in which case the timestep is a `float`.\\n\\nDepending on the context, a scheduler defines how to iteratively add noise to an image or how to update a sample based on a model's output:\\n\\n- during *training*, a scheduler adds noise (there are different algorithms for how to add noise) to a sample to train a diffusion model\\n- during *inference*, a scheduler defines how to update a sample based on a pretrained model's output\\n\\nMany schedulers are implemented from the [k-diffusion](https://github.com/crowsonkb/k-diffusion) library by [Katherine Crowson](https://github.com/crowsonkb/), and they're also widely used in A1111. To help you map the schedulers from k-diffusion and A1111 to the schedulers in ü§ó Diffusers, take a look at the table below:\\n\\n| A1111/k-diffusion    | ü§ó Diffusers                         | Usage                                                                                                         |\\n|---------------------|-------------------------------------|---------------------------------------------------------------------------------------------------------------|\\n| DPM++ 2M            | [`DPMSolverMultistepScheduler`]     |                                                                                                               |\\n| DPM++ 2M Karras     | [`DPMSolverMultistepScheduler`]     | init with `use_karras_sigmas=True`                                                                            |\\n| DPM++ 2M SDE        | [`DPMSolverMultistepScheduler`]     | init with `algorithm_type=\"sde-dpmsolver++\"`                                                                  |\\n| DPM++ 2M SDE Karras | [`DPMSolverMultistepScheduler`]     | init with `use_karras_sigmas=True` and `algorithm_type=\"sde-dpmsolver++\"`                                     |\\n| DPM++ 2S a          | N/A                                 | very similar to  `DPMSolverSinglestepScheduler`                         |\\n| DPM++ 2S a Karras   | N/A                                 | very similar to  `DPMSolverSinglestepScheduler(use_karras_sigmas=True, ...)` |\\n| DPM++ SDE           | [`DPMSolverSinglestepScheduler`]    |                                                                                                               |\\n| DPM++ SDE Karras    | [`DPMSolverSinglestepScheduler`]    | init with `use_karras_sigmas=True`                                                                            |\\n| DPM2                | [`KDPM2DiscreteScheduler`]          |                                                                                                               |\\n| DPM2 Karras         | [`KDPM2DiscreteScheduler`]          | init with `use_karras_sigmas=True`                                                                            |\\n| DPM2 a              | [`KDPM2AncestralDiscreteScheduler`] |                                                                                                               |\\n| DPM2 a Karras       | [`KDPM2AncestralDiscreteScheduler`] | init with `use_karras_sigmas=True`                                                                            |\\n| DPM adaptive        | N/A                                 |                                                                                                               |\\n| DPM fast            | N/A                                 |                                                                                                               |\\n| Euler               | [`EulerDiscreteScheduler`]          |                                                                                                               |\\n| Euler a             | [`EulerAncestralDiscreteScheduler`] |                                                                                                               |\\n| Heun                | [`HeunDiscreteScheduler`]           |                                                                                                               |\\n| LMS                 | [`LMSDiscreteScheduler`]            |                                                                                                               |\\n| LMS Karras          | [`LMSDiscreteScheduler`]            | init with `use_karras_sigmas=True`                                                                            |\\n| N/A                 | [`DEISMultistepScheduler`]          |                                                                                                               |\\n| N/A                 | [`UniPCMultistepScheduler`]         |                                                                                                               |\\n\\nAll schedulers are built from the base [`SchedulerMixin`] class which implements low level utilities shared by all schedulers.\\n\\n## SchedulerMixin\\n[[autodoc]] SchedulerMixin\\n\\n## SchedulerOutput\\n[[autodoc]] schedulers.scheduling_utils.SchedulerOutput\\n\\n## KarrasDiffusionSchedulers\\n\\n[`KarrasDiffusionSchedulers`] are a broad generalization of schedulers in ü§ó Diffusers. The schedulers in this class are distinguished at a high level by their noise sampling strategy, the type of network and scaling, the training strategy, and how the loss is weighed.\\n\\nThe different schedulers in this class, depending on the ordinary differential equations (ODE) solver type, fall into the above taxonomy and provide a good abstraction for the design of the main schedulers implemented in ü§ó Diffusers. The schedulers in this class are given [here](https://github.com/huggingface/diffusers/blob/a69754bb879ed55b9b6dc9dd0b3cf4fa4124c765/src/diffusers/schedulers/scheduling_utils.py#L32).\\n\\n## PushToHubMixin\\n\\n[[autodoc]] utils.PushToHubMixin\\n</td>\n",
              "      <td>What is the class of schedulers in ü§ó Diffusers that are distinguished by their noise sampling strategy, type of network and scaling, training strategy, and loss weighing?\\n</td>\n",
              "      <td>[`KarrasDiffusionSchedulers`]</td>\n",
              "      <td>huggingface/diffusers/blob/main/docs/source/en/api/schedulers/overview.md</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          context  \\\n",
              "0  !--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\\nthe License. You may obtain a copy of the License at\\n\\nhttp://www.apache.org/licenses/LICENSE-2.0\\n\\nUnless required by applicable law or agreed to in writing, software distributed under the License is distributed on\\nan \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\\nspecific language governing permissions and limitations under the License.\\n-->\\n\\n# Schedulers\\n\\nü§ó Diffusers provides many scheduler functions for the diffusion process. A scheduler takes a model's output (the sample which the diffusion process is iterating on) and a timestep to return a denoised sample. The timestep is important because it dictates where in the diffusion process the step is; data is generated by iterating forward *n* timesteps and inference occurs by propagating backward through the timesteps. Based on the timestep, a scheduler may be *discrete* in which case the timestep is an `int` or *continuous* in which case the timestep is a `float`.\\n\\nDepending on the context, a scheduler defines how to iteratively add noise to an image or how to update a sample based on a model's output:\\n\\n- during *training*, a scheduler adds noise (there are different algorithms for how to add noise) to a sample to train a diffusion model\\n- during *inference*, a scheduler defines how to update a sample based on a pretrained model's output\\n\\nMany schedulers are implemented from the [k-diffusion](https://github.com/crowsonkb/k-diffusion) library by [Katherine Crowson](https://github.com/crowsonkb/), and they're also widely used in A1111. To help you map the schedulers from k-diffusion and A1111 to the schedulers in ü§ó Diffusers, take a look at the table below:\\n\\n| A1111/k-diffusion    | ü§ó Diffusers                         | Usage                                                                                                         |\\n|---------------------|-------------------------------------|---------------------------------------------------------------------------------------------------------------|\\n| DPM++ 2M            | [`DPMSolverMultistepScheduler`]     |                                                                                                               |\\n| DPM++ 2M Karras     | [`DPMSolverMultistepScheduler`]     | init with `use_karras_sigmas=True`                                                                            |\\n| DPM++ 2M SDE        | [`DPMSolverMultistepScheduler`]     | init with `algorithm_type=\"sde-dpmsolver++\"`                                                                  |\\n| DPM++ 2M SDE Karras | [`DPMSolverMultistepScheduler`]     | init with `use_karras_sigmas=True` and `algorithm_type=\"sde-dpmsolver++\"`                                     |\\n| DPM++ 2S a          | N/A                                 | very similar to  `DPMSolverSinglestepScheduler`                         |\\n| DPM++ 2S a Karras   | N/A                                 | very similar to  `DPMSolverSinglestepScheduler(use_karras_sigmas=True, ...)` |\\n| DPM++ SDE           | [`DPMSolverSinglestepScheduler`]    |                                                                                                               |\\n| DPM++ SDE Karras    | [`DPMSolverSinglestepScheduler`]    | init with `use_karras_sigmas=True`                                                                            |\\n| DPM2                | [`KDPM2DiscreteScheduler`]          |                                                                                                               |\\n| DPM2 Karras         | [`KDPM2DiscreteScheduler`]          | init with `use_karras_sigmas=True`                                                                            |\\n| DPM2 a              | [`KDPM2AncestralDiscreteScheduler`] |                                                                                                               |\\n| DPM2 a Karras       | [`KDPM2AncestralDiscreteScheduler`] | init with `use_karras_sigmas=True`                                                                            |\\n| DPM adaptive        | N/A                                 |                                                                                                               |\\n| DPM fast            | N/A                                 |                                                                                                               |\\n| Euler               | [`EulerDiscreteScheduler`]          |                                                                                                               |\\n| Euler a             | [`EulerAncestralDiscreteScheduler`] |                                                                                                               |\\n| Heun                | [`HeunDiscreteScheduler`]           |                                                                                                               |\\n| LMS                 | [`LMSDiscreteScheduler`]            |                                                                                                               |\\n| LMS Karras          | [`LMSDiscreteScheduler`]            | init with `use_karras_sigmas=True`                                                                            |\\n| N/A                 | [`DEISMultistepScheduler`]          |                                                                                                               |\\n| N/A                 | [`UniPCMultistepScheduler`]         |                                                                                                               |\\n\\nAll schedulers are built from the base [`SchedulerMixin`] class which implements low level utilities shared by all schedulers.\\n\\n## SchedulerMixin\\n[[autodoc]] SchedulerMixin\\n\\n## SchedulerOutput\\n[[autodoc]] schedulers.scheduling_utils.SchedulerOutput\\n\\n## KarrasDiffusionSchedulers\\n\\n[`KarrasDiffusionSchedulers`] are a broad generalization of schedulers in ü§ó Diffusers. The schedulers in this class are distinguished at a high level by their noise sampling strategy, the type of network and scaling, the training strategy, and how the loss is weighed.\\n\\nThe different schedulers in this class, depending on the ordinary differential equations (ODE) solver type, fall into the above taxonomy and provide a good abstraction for the design of the main schedulers implemented in ü§ó Diffusers. The schedulers in this class are given [here](https://github.com/huggingface/diffusers/blob/a69754bb879ed55b9b6dc9dd0b3cf4fa4124c765/src/diffusers/schedulers/scheduling_utils.py#L32).\\n\\n## PushToHubMixin\\n\\n[[autodoc]] utils.PushToHubMixin\\n   \n",
              "\n",
              "                                                                                                                                                                       question  \\\n",
              "0  What is the class of schedulers in ü§ó Diffusers that are distinguished by their noise sampling strategy, type of network and scaling, training strategy, and loss weighing?\\n   \n",
              "\n",
              "                          answer  \\\n",
              "0  [`KarrasDiffusionSchedulers`]   \n",
              "\n",
              "                                                                  source_doc  \n",
              "0  huggingface/diffusers/blob/main/docs/source/en/api/schedulers/overview.md  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(pd.DataFrame(outputs).head(1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KG4dNtg9jVN"
      },
      "source": [
        "### 1.3. ËÆæÁΩÆÊâπÂà§Êô∫ËÉΩ‰Ωì\n",
        "\n",
        "‰πãÂâçÁöÑÊô∫ËÉΩ‰ΩìÁîüÊàêÁöÑÈóÆÈ¢òÂèØËÉΩÂ≠òÂú®ËÆ∏Â§öÁº∫Èô∑ÔºöÂú®È™åËØÅËøô‰∫õÈóÆÈ¢ò‰πãÂâçÔºåÊàë‰ª¨Â∫îËØ•ËøõË°åË¥®ÈáèÊ£ÄÊü•„ÄÇ\n",
        "\n",
        "Âõ†Ê≠§ÔºåÊàë‰ª¨ÊûÑÂª∫‰∫ÜÊâπÂà§Êô∫ËÉΩ‰ΩìÔºåÂÆÉ‰ª¨Â∞ÜÊ†πÊçÆ‰ª•‰∏ãÂá†‰∏™Ê†áÂáÜÂØπÊØè‰∏™ÈóÆÈ¢òËøõË°åËØÑÂàÜÔºåËøô‰∫õÊ†áÂáÜÂú®[ËøôÁØáËÆ∫Êñá](https://huggingface.co/papers/2312.10003)‰∏≠ÁªôÂá∫Ôºö\n",
        "- **ÂÖ∑‰ΩìÊÄßÔºàGroundednessÔºâ**ÔºöÈóÆÈ¢òÊòØÂê¶ÂèØ‰ª•‰ªéÁªôÂÆöÁöÑ‰∏ä‰∏ãÊñá‰∏≠ÂæóÂà∞ÂõûÁ≠îÔºü\n",
        "- **Áõ∏ÂÖ≥ÊÄßÔºàRelevanceÔºâ**ÔºöÈóÆÈ¢òÂØπÁî®Êà∑ÊòØÂê¶Áõ∏ÂÖ≥Ôºü‰æãÂ¶ÇÔºå`\"transformers 4.29.1 ÂèëÂ∏ÉÁöÑÊó•ÊúüÊòØ‰ªÄ‰πàÔºü\"`ÂØπ‰∫é ML Áî®Êà∑Êù•ËØ¥Âπ∂‰∏çÁõ∏ÂÖ≥„ÄÇ\n",
        "\n",
        "Êàë‰ª¨Ê≥®ÊÑèÂà∞ÁöÑ‰∏Ä‰∏™ÊúÄÂêéÁöÑÂ§±Ë¥•Ê°à‰æãÊòØÔºåÂΩì‰∏Ä‰∏™ÂáΩÊï∞ÊòØ‰∏∫ÁîüÊàêÈóÆÈ¢òÁöÑÁâπÂÆöÁéØÂ¢ÉÈáèË∫´ÂÆöÂÅöÁöÑÔºå‰ΩÜÊú¨Ë∫´Èöæ‰ª•ÁêÜËß£ÔºåÊØîÂ¶Ç`\"Ëøô‰∏™ÊåáÂçó‰∏≠‰ΩøÁî®ÁöÑÂáΩÊï∞ÁöÑÂêçÁß∞ÊòØ‰ªÄ‰πàÔºü\"`„ÄÇ\n",
        "Êàë‰ª¨‰πü‰∏∫Ëøô‰∏™Ê†áÂáÜÊûÑÂª∫‰∫Ü‰∏Ä‰∏™ÊâπÂà§Êô∫ËÉΩ‰ΩìÔºö\n",
        "- **Áã¨Á´ãÔºàStand-aloneÔºâ**ÔºöÂØπ‰∫é‰∏Ä‰∏™ÂÖ∑ÊúâÈ¢ÜÂüüÁü•ËØÜ/‰∫íËÅîÁΩëËÆøÈóÆÊùÉÈôêÁöÑ‰∫∫Êù•ËØ¥ÔºåÈóÆÈ¢òÂú®Ê≤°Êúâ‰ªª‰Ωï‰∏ä‰∏ãÊñáÁöÑÊÉÖÂÜµ‰∏ãÊòØÂê¶ÂèØ‰ª•ÁêÜËß£Ôºü‰∏éÊ≠§Áõ∏ÂèçÁöÑÊòØÔºåÂØπ‰∫é‰ªéÁâπÂÆöÂçöÂÆ¢ÊñáÁ´†ÁîüÊàêÁöÑÈóÆÈ¢òÊØîÂ¶Ç\"ËøôÁØáÊñáÁ´†‰∏≠‰ΩøÁî®ÁöÑÂáΩÊï∞ÊòØ‰ªÄ‰πàÔºü\"\n",
        "\n",
        "Êàë‰ª¨Á≥ªÁªüÂú∞Áî®ÊâÄÊúâËøô‰∫õÊô∫ËÉΩ‰ΩìÂØπÂáΩÊï∞ËøõË°åËØÑÂàÜÔºåÊØèÂΩì‰ªª‰Ωï‰∏Ä‰∏™Êô∫ËÉΩ‰ΩìÁöÑÂàÜÊï∞Â§™‰ΩéÊó∂ÔºåÊàë‰ª¨Â∞±‰ªéÊàë‰ª¨ÁöÑËØÑ‰º∞Êï∞ÊçÆÈõÜ‰∏≠Âà†Èô§Ëøô‰∏™ÈóÆÈ¢ò„ÄÇ\n",
        "\n",
        "üí° ___ÂΩìË¶ÅÊ±ÇÊô∫ËÉΩ‰ΩìËæìÂá∫ÂàÜÊï∞Êó∂ÔºåÊàë‰ª¨È¶ñÂÖàË¶ÅÊ±ÇÂÆÉ‰ª¨‰∫ßÁîüÂÖ∂ÁêÜÁî±„ÄÇËøôÂ∞ÜÂ∏ÆÂä©Êàë‰ª¨È™åËØÅÂàÜÊï∞Ôºå‰ΩÜÊúÄÈáçË¶ÅÁöÑÊòØÔºåË¶ÅÊ±ÇÂÆÉÈ¶ñÂÖàËæìÂá∫ÁêÜÁî±Áªô‰∫ÜÊ®°ÂûãÊõ¥Â§öÁöÑ token Êù•ÊÄùËÄÉÂíåËØ¶ÁªÜÈòêËø∞Á≠îÊ°àÔºåÁÑ∂ÂêéÂÜçÂ∞ÜÂÖ∂ÊÄªÁªìÊàê‰∏Ä‰∏™Âçï‰∏ÄÁöÑÂàÜÊï∞ token„ÄÇ___\n",
        "\n",
        "Êàë‰ª¨Áé∞Âú®ÊûÑÂª∫Âπ∂ËøêË°åËøô‰∫õÊâπÂà§Êô∫ËÉΩ‰Ωì„ÄÇ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05aSgTGs9jVO"
      },
      "outputs": [],
      "source": [
        "question_groundedness_critique_prompt = \"\"\"\n",
        "You will be given a context and a question.\n",
        "Your task is to provide a 'total rating' scoring how well one can answer the given question unambiguously with the given context.\n",
        "Give your answer on a scale of 1 to 5, where 1 means that the question is not answerable at all given the context, and 5 means that the question is clearly and unambiguously answerable with the context.\n",
        "\n",
        "Provide your answer as follows:\n",
        "\n",
        "Answer:::\n",
        "Evaluation: (your rationale for the rating, as a text)\n",
        "Total rating: (your rating, as a number between 1 and 5)\n",
        "\n",
        "You MUST provide values for 'Evaluation:' and 'Total rating:' in your answer.\n",
        "\n",
        "Now here are the question and context.\n",
        "\n",
        "Question: {question}\\n\n",
        "Context: {context}\\n\n",
        "Answer::: \"\"\"\n",
        "\n",
        "question_relevance_critique_prompt = \"\"\"\n",
        "You will be given a question.\n",
        "Your task is to provide a 'total rating' representing how useful this question can be to machine learning developers building NLP applications with the Hugging Face ecosystem.\n",
        "Give your answer on a scale of 1 to 5, where 1 means that the question is not useful at all, and 5 means that the question is extremely useful.\n",
        "\n",
        "Provide your answer as follows:\n",
        "\n",
        "Answer:::\n",
        "Evaluation: (your rationale for the rating, as a text)\n",
        "Total rating: (your rating, as a number between 1 and 5)\n",
        "\n",
        "You MUST provide values for 'Evaluation:' and 'Total rating:' in your answer.\n",
        "\n",
        "Now here is the question.\n",
        "\n",
        "Question: {question}\\n\n",
        "Answer::: \"\"\"\n",
        "\n",
        "question_standalone_critique_prompt = \"\"\"\n",
        "You will be given a question.\n",
        "Your task is to provide a 'total rating' representing how context-independant this question is.\n",
        "Give your answer on a scale of 1 to 5, where 1 means that the question depends on additional information to be understood, and 5 means that the question makes sense by itself.\n",
        "For instance, if the question refers to a particular setting, like 'in the context' or 'in the document', the rating must be 1.\n",
        "The questions can contain obscure technical nouns or acronyms like Gradio, Hub, Hugging Face or Space and still be a 5: it must simply be clear to an operator with access to documentation what the question is about.\n",
        "\n",
        "For instance, \"What is the name of the checkpoint from which the ViT model is imported?\" should receive a 1, since there is an implicit mention of a context, thus the question is not independant from the context.\n",
        "\n",
        "Provide your answer as follows:\n",
        "\n",
        "Answer:::\n",
        "Evaluation: (your rationale for the rating, as a text)\n",
        "Total rating: (your rating, as a number between 1 and 5)\n",
        "\n",
        "You MUST provide values for 'Evaluation:' and 'Total rating:' in your answer.\n",
        "\n",
        "Now here is the question.\n",
        "\n",
        "Question: {question}\\n\n",
        "Answer::: \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9tbk7ME9jVO"
      },
      "outputs": [],
      "source": [
        "print(\"Generating critique for each QA couple...\")\n",
        "for output in tqdm(outputs):\n",
        "    evaluations = {\n",
        "        \"groundedness\": call_llm(\n",
        "            llm_client,\n",
        "            question_groundedness_critique_prompt.format(\n",
        "                context=output[\"context\"], question=output[\"question\"]\n",
        "            ),\n",
        "        ),\n",
        "        \"relevance\": call_llm(\n",
        "            llm_client,\n",
        "            question_relevance_critique_prompt.format(question=output[\"question\"]),\n",
        "        ),\n",
        "        \"standalone\": call_llm(\n",
        "            llm_client,\n",
        "            question_standalone_critique_prompt.format(question=output[\"question\"]),\n",
        "        ),\n",
        "    }\n",
        "    try:\n",
        "        for criterion, evaluation in evaluations.items():\n",
        "            score, eval = (\n",
        "                int(evaluation.split(\"Total rating: \")[-1].strip()),\n",
        "                evaluation.split(\"Total rating: \")[-2].split(\"Evaluation: \")[1],\n",
        "            )\n",
        "            output.update(\n",
        "                {\n",
        "                    f\"{criterion}_score\": score,\n",
        "                    f\"{criterion}_eval\": eval,\n",
        "                }\n",
        "            )\n",
        "    except Exception as e:\n",
        "        continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQv36Y_f9jVO"
      },
      "source": [
        "Áé∞Âú®ËÆ©Êàë‰ª¨Âü∫‰∫éÊàë‰ª¨ÊâπÂà§Êô∫ËÉΩ‰ΩìÁöÑÂàÜÊï∞ËøáÊª§Êéâ‰∏çÂ•ΩÁöÑÈóÆÈ¢òÔºö"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBWuOu1b9jVO",
        "outputId": "b32bacea-52f8-486a-96fe-5c188605c5a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation dataset before filtering:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>groundedness_score</th>\n",
              "      <th>relevance_score</th>\n",
              "      <th>standalone_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the class of schedulers in ü§ó Diffusers that are distinguished by their noise sampling strategy, type of network and scaling, training strategy, and loss weighing?\\n</td>\n",
              "      <td>[`KarrasDiffusionSchedulers`]</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What are some utility functions provided by the Hugging Face library for pipelines?\\n</td>\n",
              "      <td>The Hugging Face library provides several utility functions for pipelines, including `ArgumentHandler`, `ZeroShotClassificationArgumentHandler`, `QuestionAnsweringArgumentHandler` for argument handling, `PipelineDataFormat`, `CsvPipelineDataFormat`, `JsonPipelineDataFormat`, `PipedPipelineDataFormat` for data format, and `PipelineException` for exceptions.</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the default name used in the Gradio demo if no name is provided?\\n</td>\n",
              "      <td>User\\n\\nExplanation: The factoid question asks for the default name used in the Gradio demo if no name is provided. The answer to this question can be found in the `argparse.ArgumentParser()` function, where a default value of \"User\" is set for the `--name` argument.</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the function used to load a pre-trained Resnet-18 model in the provided context?\\n</td>\n",
              "      <td>The function used to load a pre-trained Resnet-18 model in the provided context is `torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True).eval()`.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the name of the component used for creating a button in the given code?\\n</td>\n",
              "      <td>The name of the component used for creating a button in the given code is `BaseButton`.</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>What is the command to get the example ONNX file for Bart model?\\n</td>\n",
              "      <td>The command is `python run_onnx_exporter.py --model_name_or_path facebook/bart-base`.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>What will be covered in the next unit of the course?\\n</td>\n",
              "      <td>The next unit of the course will cover learning more about Unity MLAgents and training agents in Unity environments. It will also prepare students for AI vs AI challenges where they will train their agents to compete against other agents in a snowball fight and a soccer game.</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What is the purpose of the `negative_original_size`, `negative_crops_coords_top_left`, and `negative_target_size` parameters in SDXL?\\n</td>\n",
              "      <td>These parameters allow SDXL to negatively condition the model on image resolution and cropping parameters.</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>How are transformers models tested in the Hugging Face repository?\\n</td>\n",
              "      <td>Transformers models are tested in the Hugging Face repository using two test suites: `tests` for the general API and `examples` for various applications that aren't part of the API. These tests are run on CircleCI and GitHub Actions, with different jobs and configurations for each. The tests can be run in various ways, including running all tests, getting the list of all tests, running a specific test module, and running specific tests by name or keyword expression. Additionally, there are options for running tests in parallel, repeating tests, and running tests on a specific GPU or CPU.</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>What command is used to create a virtual environment in the given context?\\n</td>\n",
              "      <td>The command used to create a virtual environment in the given context is `python -m venv &lt;env_name&gt;`.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                       question  \\\n",
              "0  What is the class of schedulers in ü§ó Diffusers that are distinguished by their noise sampling strategy, type of network and scaling, training strategy, and loss weighing?\\n   \n",
              "1                                                                                         What are some utility functions provided by the Hugging Face library for pipelines?\\n   \n",
              "2                                                                                                    What is the default name used in the Gradio demo if no name is provided?\\n   \n",
              "3                                                                                    What is the function used to load a pre-trained Resnet-18 model in the provided context?\\n   \n",
              "4                                                                                             What is the name of the component used for creating a button in the given code?\\n   \n",
              "5                                                                                                            What is the command to get the example ONNX file for Bart model?\\n   \n",
              "6                                                                                                                        What will be covered in the next unit of the course?\\n   \n",
              "7                                       What is the purpose of the `negative_original_size`, `negative_crops_coords_top_left`, and `negative_target_size` parameters in SDXL?\\n   \n",
              "8                                                                                                          How are transformers models tested in the Hugging Face repository?\\n   \n",
              "9                                                                                                  What command is used to create a virtual environment in the given context?\\n   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               answer  \\\n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       [`KarrasDiffusionSchedulers`]   \n",
              "1                                                                                                                                                                                                                                              The Hugging Face library provides several utility functions for pipelines, including `ArgumentHandler`, `ZeroShotClassificationArgumentHandler`, `QuestionAnsweringArgumentHandler` for argument handling, `PipelineDataFormat`, `CsvPipelineDataFormat`, `JsonPipelineDataFormat`, `PipedPipelineDataFormat` for data format, and `PipelineException` for exceptions.   \n",
              "2                                                                                                                                                                                                                                                                                                                                         User\\n\\nExplanation: The factoid question asks for the default name used in the Gradio demo if no name is provided. The answer to this question can be found in the `argparse.ArgumentParser()` function, where a default value of \"User\" is set for the `--name` argument.   \n",
              "3                                                                                                                                                                                                                                                                                                                                                                                                                                                   The function used to load a pre-trained Resnet-18 model in the provided context is `torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True).eval()`.   \n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             The name of the component used for creating a button in the given code is `BaseButton`.   \n",
              "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               The command is `python run_onnx_exporter.py --model_name_or_path facebook/bart-base`.   \n",
              "6                                                                                                                                                                                                                                                                                                                                The next unit of the course will cover learning more about Unity MLAgents and training agents in Unity environments. It will also prepare students for AI vs AI challenges where they will train their agents to compete against other agents in a snowball fight and a soccer game.   \n",
              "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          These parameters allow SDXL to negatively condition the model on image resolution and cropping parameters.   \n",
              "8  Transformers models are tested in the Hugging Face repository using two test suites: `tests` for the general API and `examples` for various applications that aren't part of the API. These tests are run on CircleCI and GitHub Actions, with different jobs and configurations for each. The tests can be run in various ways, including running all tests, getting the list of all tests, running a specific test module, and running specific tests by name or keyword expression. Additionally, there are options for running tests in parallel, repeating tests, and running tests on a specific GPU or CPU.   \n",
              "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               The command used to create a virtual environment in the given context is `python -m venv <env_name>`.   \n",
              "\n",
              "   groundedness_score  relevance_score  standalone_score  \n",
              "0                 3.0              1.0               4.0  \n",
              "1                 5.0              4.0               5.0  \n",
              "2                 5.0              3.0               5.0  \n",
              "3                 NaN              NaN               NaN  \n",
              "4                 5.0              1.0               5.0  \n",
              "5                 NaN              NaN               NaN  \n",
              "6                 5.0              1.0               5.0  \n",
              "7                 2.0              4.0               2.0  \n",
              "8                 3.0              4.0               4.0  \n",
              "9                 NaN              NaN               NaN  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================\n",
            "Final evaluation dataset:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>groundedness_score</th>\n",
              "      <th>relevance_score</th>\n",
              "      <th>standalone_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What are some utility functions provided by the Hugging Face library for pipelines?\\n</td>\n",
              "      <td>The Hugging Face library provides several utility functions for pipelines, including `ArgumentHandler`, `ZeroShotClassificationArgumentHandler`, `QuestionAnsweringArgumentHandler` for argument handling, `PipelineDataFormat`, `CsvPipelineDataFormat`, `JsonPipelineDataFormat`, `PipedPipelineDataFormat` for data format, and `PipelineException` for exceptions.</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                question  \\\n",
              "1  What are some utility functions provided by the Hugging Face library for pipelines?\\n   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                   answer  \\\n",
              "1  The Hugging Face library provides several utility functions for pipelines, including `ArgumentHandler`, `ZeroShotClassificationArgumentHandler`, `QuestionAnsweringArgumentHandler` for argument handling, `PipelineDataFormat`, `CsvPipelineDataFormat`, `JsonPipelineDataFormat`, `PipedPipelineDataFormat` for data format, and `PipelineException` for exceptions.   \n",
              "\n",
              "   groundedness_score  relevance_score  standalone_score  \n",
              "1                 5.0              4.0               5.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "\n",
        "generated_questions = pd.DataFrame.from_dict(outputs)\n",
        "\n",
        "print(\"Evaluation dataset before filtering:\")\n",
        "display(\n",
        "    generated_questions[\n",
        "        [\n",
        "            \"question\",\n",
        "            \"answer\",\n",
        "            \"groundedness_score\",\n",
        "            \"relevance_score\",\n",
        "            \"standalone_score\",\n",
        "        ]\n",
        "    ]\n",
        ")\n",
        "generated_questions = generated_questions.loc[\n",
        "    (generated_questions[\"groundedness_score\"] >= 4)\n",
        "    & (generated_questions[\"relevance_score\"] >= 4)\n",
        "    & (generated_questions[\"standalone_score\"] >= 4)\n",
        "]\n",
        "print(\"============================================\")\n",
        "print(\"Final evaluation dataset:\")\n",
        "display(\n",
        "    generated_questions[\n",
        "        [\n",
        "            \"question\",\n",
        "            \"answer\",\n",
        "            \"groundedness_score\",\n",
        "            \"relevance_score\",\n",
        "            \"standalone_score\",\n",
        "        ]\n",
        "    ]\n",
        ")\n",
        "\n",
        "eval_dataset = datasets.Dataset.from_pandas(\n",
        "    generated_questions, split=\"train\", preserve_index=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaOMZyu69jVO"
      },
      "source": [
        "Áé∞Âú®Êàë‰ª¨ÂêàÊàêËØÑ‰º∞Êï∞ÊçÆÈõÜÂ∑≤ÂÆåÊàêÔºÅÊàë‰ª¨ÂèØ‰ª•Âú®Ëøô‰∏™ËØÑ‰º∞Êï∞ÊçÆÈõÜ‰∏äËØÑ‰º∞‰∏çÂêåÁöÑ RAG Á≥ªÁªü„ÄÇ\n",
        "\n",
        "Êàë‰ª¨Âú®ËøôÈáåÂè™ÁîüÊàê‰∫ÜÂ∞ëÊï∞Âá†‰∏™ÈóÆÁ≠îÂØπÔºå‰ª•ÂáèÂ∞ëÊó∂Èó¥ÂíåÊàêÊú¨„ÄÇ‰∏ãÈù¢ÔºåËÆ©Êàë‰ª¨ÈÄöËøáÂä†ËΩΩ‰∏Ä‰∏™È¢ÑÂÖàÁîüÊàêÁöÑÊï∞ÊçÆÈõÜÊù•ËøõË°å‰∏ã‰∏ÄÈÉ®ÂàÜÔºö"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3RRz4W79jVO"
      },
      "outputs": [],
      "source": [
        "eval_dataset = datasets.load_dataset(\"m-ric/huggingface_doc_qa_eval\", split=\"train\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5s19uTd9jVO"
      },
      "source": [
        "# 2. ÊûÑÂª∫Êàë‰ª¨ÁöÑ RAG Á≥ªÁªü"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-mET8Dy9jVO"
      },
      "source": [
        "### 2.1. È¢ÑÂ§ÑÁêÜÊñáÊ°£Êù•ÊûÑÂª∫Êàë‰ª¨ÁöÑÂêëÈáèÊï∞ÊçÆÂ∫ì\n",
        "\n",
        "- Âú®Ëøô‰∏ÄÈÉ®ÂàÜÔºå__Êàë‰ª¨Â∞ÜÁü•ËØÜÂ∫ì‰∏≠ÁöÑÊñáÊ°£ÂàÜÂâ≤ÊàêÊõ¥Â∞èÁöÑÁâáÊÆµ__ÔºöËøô‰∫õÂ∞ÜÊòØË¢´Ê£ÄÁ¥¢Âô®ÈÄâÂèñÁöÑÁâáÊÆµÔºåÁÑ∂ÂêéË¢´ÈòÖËØªÂô® LLM ‰Ωú‰∏∫ÊîØÊåÅÂÖ∂Á≠îÊ°àÁöÑÂÖÉÁ¥†„ÄÇ\n",
        "- ÁõÆÊ†áÊòØÊûÑÂª∫ËØ≠‰πâ‰∏äÁõ∏ÂÖ≥ÁöÑÁâáÊÆµÔºö‰∏çË¶ÅÂ§™Â∞èÔºå‰ª•ÂÖç‰∏çË∂≥‰ª•ÊîØÊåÅÁ≠îÊ°àÔºå‰πü‰∏çË¶ÅÂ§™Â§ßÔºå‰ª•ÂÖçÁ®ÄÈáäÂçï‰∏™ÂÜÖÂÆπ„ÄÇ\n",
        "\n",
        "ÊñáÊú¨ÂàÜÂâ≤ÊúâËÆ∏Â§öÈÄâÈ°πÔºö\n",
        "- ÊØèÈöî `n` ‰∏™ÂçïËØç/Â≠óÁ¨¶ÂàÜÂâ≤Ôºå‰ΩÜËøôÊúâÂèØËÉΩÂâ≤Ë£ÇÊÆµËêΩÁîöËá≥Âè•Â≠ê\n",
        "- Âú® `n` ‰∏™ÂçïËØç/Â≠óÁ¨¶ÂêéÂàÜÂâ≤Ôºå‰ΩÜÂè™Âú®Âè•Â≠êËæπÁïåÂ§Ñ\n",
        "- **ÈÄíÂΩíÂàÜÂâ≤** Â∞ùËØïÈÄöËøáÊ†ëÁä∂Â§ÑÁêÜÊñáÊ°£Êù•‰øùÁïôÊõ¥Â§öÊñáÊ°£ÁªìÊûÑÔºåÈ¶ñÂÖàÂú®ÊúÄÂ§ßÂçïÂÖÉÔºàÁ´†ËäÇÔºâ‰∏äÂàÜÂâ≤ÔºåÁÑ∂ÂêéÈÄíÂΩíÂú∞Âú®Êõ¥Â∞èÂçïÂÖÉÔºàÊÆµËêΩÔºåÂè•Â≠êÔºâ‰∏äÂàÜÂâ≤„ÄÇ\n",
        "Ë¶Å‰∫ÜËß£Êõ¥Â§öÂÖ≥‰∫éÂàÜÂùóÁöÑ‰ø°ÊÅØÔºåÊàëÂª∫ËÆÆ‰Ω†ÈòÖËØªÁî± Greg Kamradt ÁºñÂÜôÁöÑ[‰∏çÈîôÁöÑÊïôÁ®ã](https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/5_Levels_Of_Text_Splitting.ipynb) „ÄÇ\n",
        "\n",
        "[Ëøô‰∏™ space](https://huggingface.co/spaces/m-ric/chunk_visualizer) ËÆ©‰Ω†ÂèØËßÜÂåñ‰∏çÂêåÁöÑÂàÜÂâ≤ÈÄâÈ°πÊòØÂ¶Ç‰ΩïÂΩ±Âìç‰Ω†ÂæóÂà∞ÁöÑÁâáÊÆµÁöÑÊµÅÁ®ã„ÄÇ\n",
        "\n",
        "> Âú®‰ª•‰∏ãÂÜÖÂÆπ‰∏≠ÔºåÊàë‰ª¨‰ΩøÁî® Langchain ÁöÑ `RecursiveCharacterTextSplitter`„ÄÇ\n",
        "üí° _‰∏∫‰∫ÜÂú®Êàë‰ª¨ÁöÑÊñáÊú¨ÂàÜÂâ≤Âô®‰∏≠ÊµãÈáèÁâáÊÆµÈïøÂ∫¶ÔºåÊàë‰ª¨ÁöÑÈïøÂ∫¶ÂáΩÊï∞Â∞Ü‰∏çÊòØÂ≠óÁ¨¶ÁöÑÊï∞ÈáèÔºåËÄåÊòØ token ÂåñÊñáÊú¨‰∏≠ÁöÑ token Êï∞ÈáèÔºöÂÆûÈôÖ‰∏äÔºåÂØπ‰∫éÂêéÁª≠Â§ÑÁêÜ token ÁöÑÂµåÂÖ•Âô®Êù•ËØ¥Ôºå‰ª• token ‰∏∫Âçï‰ΩçÊµãÈáèÈïøÂ∫¶Êõ¥‰∏∫Áõ∏ÂÖ≥ÔºåÂπ∂‰∏îÂú®ÁªèÈ™å‰∏äË°®Áé∞Êõ¥Â•Ω._\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4fhm55Q9jVO"
      },
      "outputs": [],
      "source": [
        "from langchain.docstore.document import Document as LangchainDocument\n",
        "\n",
        "RAW_KNOWLEDGE_BASE = [\n",
        "    LangchainDocument(page_content=doc[\"text\"], metadata={\"source\": doc[\"source\"]})\n",
        "    for doc in tqdm(ds)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sz9Jw2_q9jVO"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "\n",
        "def split_documents(\n",
        "    chunk_size: int,\n",
        "    knowledge_base: List[LangchainDocument],\n",
        "    tokenizer_name: str,\n",
        ") -> List[LangchainDocument]:\n",
        "    \"\"\"\n",
        "    Split documents into chunks of size `chunk_size` characters and return a list of documents.\n",
        "    \"\"\"\n",
        "    text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
        "        AutoTokenizer.from_pretrained(tokenizer_name),\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=int(chunk_size / 10),\n",
        "        add_start_index=True,\n",
        "        strip_whitespace=True,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
        "    )\n",
        "\n",
        "    docs_processed = []\n",
        "    for doc in knowledge_base:\n",
        "        docs_processed += text_splitter.split_documents([doc])\n",
        "\n",
        "    # Remove duplicates\n",
        "    unique_texts = {}\n",
        "    docs_processed_unique = []\n",
        "    for doc in docs_processed:\n",
        "        if doc.page_content not in unique_texts:\n",
        "            unique_texts[doc.page_content] = True\n",
        "            docs_processed_unique.append(doc)\n",
        "\n",
        "    return docs_processed_unique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzBYfNG79jVO"
      },
      "source": [
        "### 2.2.  Ê£ÄÁ¥¢Âô® - ÂµåÂÖ• üóÇÔ∏è\n",
        "\n",
        "__Ê£ÄÁ¥¢Âô®ÁöÑ‰ΩúÁî®Á±ª‰ºº‰∫éÂÜÖÈÉ®ÊêúÁ¥¢ÂºïÊìé__ÔºöÁªôÂÆöÁî®Êà∑Êü•ËØ¢ÔºåÂÆÉ‰ªé‰Ω†ÁöÑÁü•ËØÜÂ∫ì‰∏≠ËøîÂõûÊúÄÁõ∏ÂÖ≥ÁöÑÊñáÊ°£„ÄÇ\n",
        "\n",
        "> ÂØπ‰∫éÁü•ËØÜÂ∫ìÔºåÊàë‰ª¨‰ΩøÁî® Langchain ÂêëÈáèÊï∞ÊçÆÂ∫ìÔºåÂõ†‰∏∫ÂÆÉÊèê‰æõ‰∫Ü‰∏Ä‰∏™Êñπ‰æøÁöÑ [FAISS](https://github.com/facebookresearch/faiss) Á¥¢ÂºïÔºåÂπ∂ÂÖÅËÆ∏Êàë‰ª¨Âú®Êï¥‰∏™Â§ÑÁêÜËøáÁ®ã‰∏≠‰øùÁïôÊñáÊ°£ÂÖÉÊï∞ÊçÆ„ÄÇ\n",
        "\n",
        "üõ†Ô∏è __ÂåÖÂê´ÂèØÈÄâÈ°πÔºö__\n",
        "\n",
        "- Ë∞ÉÊï¥ÂàÜÂùóÊñπÊ≥ïÔºö\n",
        "    - ÁâáÊÆµ(chunks)ÁöÑÂ§ßÂ∞è\n",
        "    - ÊñπÊ≥ïÔºöÂú®‰∏çÂêåÁöÑÂàÜÈöîÁ¨¶‰∏äÂàÜÂâ≤Ôºå‰ΩøÁî®[ËØ≠‰πâÂàÜÂùó](https://python.langchain.com/docs/modules/data_connection/document_transformers/semantic-chunker)...\n",
        "- Êõ¥ÊîπÂµåÂÖ•Ê®°Âûã"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqJlIDZR9jVO"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores.utils import DistanceStrategy\n",
        "import os\n",
        "\n",
        "\n",
        "def load_embeddings(\n",
        "    langchain_docs: List[LangchainDocument],\n",
        "    chunk_size: int,\n",
        "    embedding_model_name: Optional[str] = \"thenlper/gte-small\",\n",
        ") -> FAISS:\n",
        "    \"\"\"\n",
        "    Creates a FAISS index from the given embedding model and documents. Loads the index directly if it already exists.\n",
        "\n",
        "    Args:\n",
        "        langchain_docs: list of documents\n",
        "        chunk_size: size of the chunks to split the documents into\n",
        "        embedding_model_name: name of the embedding model to use\n",
        "\n",
        "    Returns:\n",
        "        FAISS index\n",
        "    \"\"\"\n",
        "    # load embedding_model\n",
        "    embedding_model = HuggingFaceEmbeddings(\n",
        "        model_name=embedding_model_name,\n",
        "        multi_process=True,\n",
        "        model_kwargs={\"device\": \"cuda\"},\n",
        "        encode_kwargs={\n",
        "            \"normalize_embeddings\": True\n",
        "        },  # set True to compute cosine similarity\n",
        "    )\n",
        "\n",
        "    # Check if embeddings already exist on disk\n",
        "    index_name = (\n",
        "        f\"index_chunk:{chunk_size}_embeddings:{embedding_model_name.replace('/', '~')}\"\n",
        "    )\n",
        "    index_folder_path = f\"./data/indexes/{index_name}/\"\n",
        "    if os.path.isdir(index_folder_path):\n",
        "        return FAISS.load_local(\n",
        "            index_folder_path,\n",
        "            embedding_model,\n",
        "            distance_strategy=DistanceStrategy.COSINE,\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        print(\"Index not found, generating it...\")\n",
        "        docs_processed = split_documents(\n",
        "            chunk_size,\n",
        "            langchain_docs,\n",
        "            embedding_model_name,\n",
        "        )\n",
        "        knowledge_index = FAISS.from_documents(\n",
        "            docs_processed, embedding_model, distance_strategy=DistanceStrategy.COSINE\n",
        "        )\n",
        "        knowledge_index.save_local(index_folder_path)\n",
        "        return knowledge_index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6y1mQJX9jVO"
      },
      "source": [
        "### 2.3. ÈòÖËØªÂô® - LLM üí¨\n",
        "\n",
        "Âú®Ëøô‰∏ÄÈÉ®ÂàÜÔºå__LLM ÈòÖËØªÂô®ËØªÂèñÊ£ÄÁ¥¢Âà∞ÁöÑÊñáÊ°£‰ª•ÂΩ¢ÊàêÂÖ∂Á≠îÊ°à„ÄÇ__\n",
        "\n",
        "üõ†Ô∏è ‰∏∫‰∫ÜÊîπÂñÑÁªìÊûúÔºåÊàë‰ª¨Â∞ùËØï‰∫Ü‰ª•‰∏ãÈÄâÈ°πÔºö\n",
        "- ÂàáÊç¢ÈáçÊéíÂ∫èÂºÄÂêØÊàñÂÖ≥Èó≠ÁöÑÁä∂ÊÄÅ\n",
        "- Êõ¥ÊîπÈòÖËØªÂô®Ê®°Âûã"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PdpuWyP9jVP"
      },
      "outputs": [],
      "source": [
        "RAG_PROMPT_TEMPLATE = \"\"\"\n",
        "<|system|>\n",
        "Using the information contained in the context,\n",
        "give a comprehensive answer to the question.\n",
        "Respond only to the question asked, response should be concise and relevant to the question.\n",
        "Provide the number of the source document when relevant.\n",
        "If the answer cannot be deduced from the context, do not give an answer.</s>\n",
        "<|user|>\n",
        "Context:\n",
        "{context}\n",
        "---\n",
        "Now here is the question you need to answer.\n",
        "\n",
        "Question: {question}\n",
        "</s>\n",
        "<|assistant|>\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SDqenld9jVP"
      },
      "outputs": [],
      "source": [
        "from langchain_community.llms import HuggingFaceHub\n",
        "\n",
        "repo_id = \"HuggingFaceH4/zephyr-7b-beta\"\n",
        "READER_MODEL_NAME = \"zephyr-7b-beta\"\n",
        "HF_API_TOKEN = \"\"\n",
        "\n",
        "READER_LLM = HuggingFaceHub(\n",
        "    repo_id=repo_id,\n",
        "    task=\"text-generation\",\n",
        "    huggingfacehub_api_token=HF_API_TOKEN,\n",
        "    model_kwargs={\n",
        "        \"max_new_tokens\": 512,\n",
        "        \"top_k\": 30,\n",
        "        \"temperature\": 0.1,\n",
        "        \"repetition_penalty\": 1.03,\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZ62CbcZ9jVP"
      },
      "outputs": [],
      "source": [
        "from ragatouille import RAGPretrainedModel\n",
        "from langchain_core.vectorstores import VectorStore\n",
        "from langchain_core.language_models.llms import LLM\n",
        "\n",
        "\n",
        "def answer_with_rag(\n",
        "    question: str,\n",
        "    llm: LLM,\n",
        "    knowledge_index: VectorStore,\n",
        "    reranker: Optional[RAGPretrainedModel] = None,\n",
        "    num_retrieved_docs: int = 30,\n",
        "    num_docs_final: int = 7,\n",
        ") -> Tuple[str, List[LangchainDocument]]:\n",
        "    \"\"\"Answer a question using RAG with the given knowledge index.\"\"\"\n",
        "    # Gather documents with retriever\n",
        "    relevant_docs = knowledge_index.similarity_search(\n",
        "        query=question, k=num_retrieved_docs\n",
        "    )\n",
        "    relevant_docs = [doc.page_content for doc in relevant_docs]  # keep only the text\n",
        "\n",
        "    # Optionally rerank results\n",
        "    if reranker:\n",
        "        relevant_docs = reranker.rerank(question, relevant_docs, k=num_docs_final)\n",
        "        relevant_docs = [doc[\"content\"] for doc in relevant_docs]\n",
        "\n",
        "    relevant_docs = relevant_docs[:num_docs_final]\n",
        "\n",
        "    # Build the final prompt\n",
        "    context = \"\\nExtracted documents:\\n\"\n",
        "    context += \"\".join(\n",
        "        [f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(relevant_docs)]\n",
        "    )\n",
        "\n",
        "    final_prompt = RAG_PROMPT_TEMPLATE.format(question=question, context=context)\n",
        "\n",
        "    # Redact an answer\n",
        "    answer = llm(final_prompt)\n",
        "\n",
        "    return answer, relevant_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiygbqfT9jVP"
      },
      "source": [
        "# 3. ÂØπ RAG Á≥ªÁªüËøõË°åÂü∫ÂáÜÊµãËØï\n",
        "\n",
        "RAG Á≥ªÁªüÂíåËØÑ‰º∞Êï∞ÊçÆÈõÜÁé∞Âú®ÂáÜÂ§áÂ•Ω‰∫Ü„ÄÇÊúÄÂêé‰∏ÄÊ≠•ÊòØÂú®Ëøô‰∏™ËØÑ‰º∞Êï∞ÊçÆÈõÜ‰∏äÂà§Êñ≠ RAG Á≥ªÁªüÁöÑËæìÂá∫„ÄÇ\n",
        "‰∏∫Ê≠§Ôºå__Êàë‰ª¨ËÆæÁΩÆ‰∫Ü‰∏Ä‰∏™Ë£ÅÂà§Êô∫ËÉΩ‰Ωì__„ÄÇ ‚öñÔ∏èü§ñ\n",
        "\n",
        "Âú®[‰∏çÂêåÁöÑ RAG ËØÑ‰º∞ÊåáÊ†á](https://docs.ragas.io/en/latest/concepts/metrics/index.html)‰∏≠ÔºåÊàë‰ª¨ÈÄâÊã©Âè™ÂÖ≥Ê≥®Âø†ÂÆûÂ∫¶ÔºåÂõ†‰∏∫ËøôÊòØË°°ÈáèÊàë‰ª¨Á≥ªÁªüÊÄßËÉΩÁöÑÊúÄ‰Ω≥ÁöÑÁ´ØÂà∞Á´ØÊåáÊ†á„ÄÇ\n",
        "\n",
        "> Êàë‰ª¨‰ΩøÁî® GPT4 ‰Ωú‰∏∫ËØÑÂà§ËÄÖÔºåÂõ†‰∏∫ÂÆÉÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠Ë°®Áé∞ËâØÂ•ΩÔºå‰ΩÜ‰Ω†‰πüÂèØ‰ª•Â∞ùËØïÂÖ∂‰ªñÊ®°ÂûãÔºå‰æãÂ¶Ç [kaist-ai/prometheus-13b-v1.0](https://huggingface.co/kaist-ai/prometheus-13b-v1.0) Êàñ [BAAI/JudgeLM-33B-v1.0](https://huggingface.co/BAAI/JudgeLM-33B-v1.0)„ÄÇ\n",
        "\n",
        "üí° _Âú®ËØÑ‰º∞ÊèêÁ§∫‰∏≠ÔºåÊàë‰ª¨ÁªôÂá∫‰∫ÜÊØè‰∏™ÊåáÊ†áÁöÑËØ¶ÁªÜÊèèËø∞ÔºåÈááÁî® 1-5 ÂàÜÁöÑËØÑÂàÜÂàªÂ∫¶ÔºåÊ≠£Â¶Ç [Prometheus ÁöÑÊèêÁ§∫Ê®°Êùø](https://huggingface.co/kaist-ai/prometheus-13b-v1.0) ÊâÄÂÅöÁöÑÈÇ£Ê†∑ÔºöËøôÊúâÂä©‰∫éÊ®°ÂûãÁ≤æÁ°ÆÂú∞Á°ÆÂÆöÂÖ∂ÊåáÊ†á„ÄÇÂ¶ÇÊûú‰Ω†ÁªôËØÑÂà§ LLM ‰∏Ä‰∏™Ê®°Á≥äÁöÑËØÑÂàÜÂàªÂ∫¶ÔºåÈÇ£‰πà‰∏çÂêåÁ§∫‰æã‰πãÈó¥ÁöÑËæìÂá∫Â∞Ü‰∏çÂ§ü‰∏ÄËá¥„ÄÇ_\n",
        "\n",
        "üí° _ÂÜçÊ¨°ÊèêÁ§∫ LLM Âú®ÁªôÂá∫ÊúÄÁªàËØÑÂàÜ‰πãÂâçÂÖàËæìÂá∫ÂÖ∂ÁêÜÁî±ÔºåËøôÊ†∑ÂÆÉÂ∞±ÊúâÊõ¥Â§öÁöÑ token Êù•Â∏ÆÂä©ÂÆÉÊ≠£ÂºèÂåñÂíåËØ¶ÁªÜÈòêËø∞ËØÑÂà§„ÄÇ_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrlMh_ZI9jVP"
      },
      "outputs": [],
      "source": [
        "from langchain_core.language_models import BaseChatModel\n",
        "\n",
        "def run_rag_tests(\n",
        "    eval_dataset: datasets.Dataset,\n",
        "    llm,\n",
        "    knowledge_index: VectorStore,\n",
        "    output_file: str,\n",
        "    reranker: Optional[RAGPretrainedModel] = None,\n",
        "    verbose: Optional[bool] = True,\n",
        "    test_settings: Optional[str] = None,  # To document the test settings used\n",
        "):\n",
        "    \"\"\"Runs RAG tests on the given dataset and saves the results to the given output file.\"\"\"\n",
        "    try:  # load previous generations if they exist\n",
        "        with open(output_file, \"r\") as f:\n",
        "            outputs = json.load(f)\n",
        "    except:\n",
        "        outputs = []\n",
        "\n",
        "    for example in tqdm(eval_dataset):\n",
        "        question = example[\"question\"]\n",
        "        if question in [output[\"question\"] for output in outputs]:\n",
        "            continue\n",
        "\n",
        "        answer, relevant_docs = answer_with_rag(\n",
        "            question, llm, knowledge_index, reranker=reranker\n",
        "        )\n",
        "        if verbose:\n",
        "            print(\"=======================================================\")\n",
        "            print(f\"Question: {question}\")\n",
        "            print(f\"Answer: {answer}\")\n",
        "            print(f'True answer: {example[\"answer\"]}')\n",
        "        result = {\n",
        "            \"question\": question,\n",
        "            \"true_answer\": example[\"answer\"],\n",
        "            \"source_doc\": example[\"source_doc\"],\n",
        "            \"generated_answer\": answer,\n",
        "            \"retrieved_docs\": [doc for doc in relevant_docs],\n",
        "        }\n",
        "        if test_settings:\n",
        "            result[\"test_settings\"] = test_settings\n",
        "        outputs.append(result)\n",
        "\n",
        "        with open(output_file, \"w\") as f:\n",
        "            json.dump(outputs, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ae-3KWzK9jVP"
      },
      "outputs": [],
      "source": [
        "EVALUATION_PROMPT = \"\"\"###Task Description:\n",
        "An instruction (might include an Input inside it), a response to evaluate, a reference answer that gets a score of 5, and a score rubric representing a evaluation criteria are given.\n",
        "1. Write a detailed feedback that assess the quality of the response strictly based on the given score rubric, not evaluating in general.\n",
        "2. After writing a feedback, write a score that is an integer between 1 and 5. You should refer to the score rubric.\n",
        "3. The output format should look as follows: \\\"Feedback: {{write a feedback for criteria}} [RESULT] {{an integer number between 1 and 5}}\\\"\n",
        "4. Please do not generate any other opening, closing, and explanations. Be sure to include [RESULT] in your output.\n",
        "\n",
        "###The instruction to evaluate:\n",
        "{instruction}\n",
        "\n",
        "###Response to evaluate:\n",
        "{response}\n",
        "\n",
        "###Reference Answer (Score 5):\n",
        "{reference_answer}\n",
        "\n",
        "###Score Rubrics:\n",
        "[Is the response correct, accurate, and factual based on the reference answer?]\n",
        "Score 1: The response is completely incorrect, inaccurate, and/or not factual.\n",
        "Score 2: The response is mostly incorrect, inaccurate, and/or not factual.\n",
        "Score 3: The response is somewhat correct, accurate, and/or factual.\n",
        "Score 4: The response is mostly correct, accurate, and factual.\n",
        "Score 5: The response is completely correct, accurate, and factual.\n",
        "\n",
        "###Feedback:\"\"\"\n",
        "\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import SystemMessage\n",
        "\n",
        "\n",
        "evaluation_prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        SystemMessage(content=\"You are a fair evaluator language model.\"),\n",
        "        HumanMessagePromptTemplate.from_template(EVALUATION_PROMPT),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ia9Mvn859jVP"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "OPENAI_API_KEY = \"\"\n",
        "\n",
        "eval_chat_model = ChatOpenAI(model=\"gpt-4-1106-preview\", temperature=0, openai_api_key=OPENAI_API_KEY)\n",
        "evaluator_name = \"GPT4\"\n",
        "\n",
        "\n",
        "def evaluate_answers(\n",
        "    answer_path: str,\n",
        "    eval_chat_model,\n",
        "    evaluator_name: str,\n",
        "    evaluation_prompt_template: ChatPromptTemplate,\n",
        ") -> None:\n",
        "    \"\"\"Evaluates generated answers. Modifies the given answer file in place for better checkpointing.\"\"\"\n",
        "    answers = []\n",
        "    if os.path.isfile(answer_path):  # load previous generations if they exist\n",
        "        answers = json.load(open(answer_path, \"r\"))\n",
        "\n",
        "    for experiment in tqdm(answers):\n",
        "        if f\"eval_score_{evaluator_name}\" in experiment:\n",
        "            continue\n",
        "\n",
        "        eval_prompt = evaluation_prompt_template.format_messages(\n",
        "            instruction=experiment[\"question\"],\n",
        "            response=experiment[\"generated_answer\"],\n",
        "            reference_answer=experiment[\"true_answer\"],\n",
        "        )\n",
        "        eval_result = eval_chat_model.invoke(eval_prompt)\n",
        "        feedback, score = [\n",
        "            item.strip() for item in eval_result.content.split(\"[RESULT]\")\n",
        "        ]\n",
        "        experiment[f\"eval_score_{evaluator_name}\"] = score\n",
        "        experiment[f\"eval_feedback_{evaluator_name}\"] = feedback\n",
        "\n",
        "        with open(answer_path, \"w\") as f:\n",
        "            json.dump(answers, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXH-szLe9jVP"
      },
      "source": [
        "üöÄ ËÆ©Êàë‰ª¨ËøêË°å‰∏Ä‰∏ãÊµãËØïÂíåËØÑ‰º∞‰∏Ä‰∏ãÁ≠îÊ°à!üëá"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jW2nnvUT9jVQ"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(\"./output\"):\n",
        "    os.mkdir(\"./output\")\n",
        "\n",
        "for chunk_size in [200]:  # Add other chunk sizes (in tokens) as needed\n",
        "    for embeddings in [\"thenlper/gte-small\"]:  # Add other embeddings as needed\n",
        "        for rerank in [True, False]:\n",
        "            settings_name = f\"chunk:{chunk_size}_embeddings:{embeddings.replace('/', '~')}_rerank:{rerank}_reader-model:{READER_MODEL_NAME}\"\n",
        "            output_file_name = f\"./output/rag_{settings_name}.json\"\n",
        "\n",
        "            print(f\"Running evaluation for {settings_name}:\")\n",
        "\n",
        "            print(\"Loading knowledge base embeddings...\")\n",
        "            knowledge_index = load_embeddings(\n",
        "                RAW_KNOWLEDGE_BASE,\n",
        "                chunk_size=chunk_size,\n",
        "                embedding_model_name=embeddings,\n",
        "            )\n",
        "\n",
        "            print(\"Running RAG...\")\n",
        "            reranker = (\n",
        "                RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")\n",
        "                if rerank\n",
        "                else None\n",
        "            )\n",
        "            run_rag_tests(\n",
        "                eval_dataset=eval_dataset,\n",
        "                llm=READER_LLM,\n",
        "                knowledge_index=knowledge_index,\n",
        "                output_file=output_file_name,\n",
        "                reranker=reranker,\n",
        "                verbose=False,\n",
        "                test_settings=settings_name,\n",
        "            )\n",
        "\n",
        "            print(\"Running evaluation...\")\n",
        "            evaluate_answers(\n",
        "                output_file_name,\n",
        "                eval_chat_model,\n",
        "                evaluator_name,\n",
        "                evaluation_prompt_template,\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tytXV5-h9jVT"
      },
      "source": [
        "### Ê£ÄÊü•ÁªìÊûú"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4YDSfmr9jVT"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "outputs = []\n",
        "for file in glob.glob(\"./output/*.json\"):\n",
        "    output = pd.DataFrame(json.load(open(file, \"r\")))\n",
        "    output[\"settings\"] = file\n",
        "    outputs.append(output)\n",
        "result = pd.concat(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdkXMNvS9jVT"
      },
      "outputs": [],
      "source": [
        "result[\"eval_score_GPT4\"] = result[\"eval_score_GPT4\"].apply(\n",
        "    lambda x: int(x) if isinstance(x, str) else 1\n",
        ")\n",
        "result[\"eval_score_GPT4\"] = (result[\"eval_score_GPT4\"] - 1) / 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgxBpid29jVT",
        "outputId": "9a3bcf32-4b0c-4df1-c76c-3ebbca82929d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "settings\n",
              "./output/rag_chunk:200_embeddings:thenlper~gte-small_rerank:False_reader-model:zephyr-7b-beta.json       0.884328\n",
              "./output/rag_chunk:200_embeddings:BAAI~bge-base-en-v1.5_rerank:False_reader-model:zephyr-7b-beta.json    0.906716\n",
              "./output/rag_chunk:200_embeddings:BAAI~bge-base-en-v1.5_rerank:True_reader-model:zephyr-7b-beta.json     0.906716\n",
              "./output/rag_chunk:200_embeddings:thenlper~gte-small_rerank:True_reader-model:mixtral.json               0.906716\n",
              "./output/rag_chunk:200_embeddings:thenlper~gte-small_rerank:True_reader-model:zephyr-7b-beta.json        0.921642\n",
              "./output/rag_chunk:200_embeddings:thenlper~gte-small_rerank:True_reader-model:mixtral0.json              0.947761\n",
              "Name: eval_score_GPT4, dtype: float64"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "average_scores = result.groupby(\"settings\")[\"eval_score_GPT4\"].mean()\n",
        "average_scores.sort_values()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSPH9DYI9jVT"
      },
      "source": [
        "## ÁªìÊûúÁ§∫‰æã\n",
        "\n",
        "ËÆ©Êàë‰ª¨Âä†ËΩΩÈÄöËøáË∞ÉÊï¥Ëøô‰∏™ notebook ‰∏≠ÂèØÁî®ÁöÑ‰∏çÂêåÈÄâÈ°πÊâÄËé∑ÂæóÁöÑÁªìÊûú„ÄÇÂÖ≥‰∫éËøô‰∫õÈÄâÈ°π‰∏∫‰ΩïÊúâÊïàÊàñÊó†ÊïàÁöÑÊõ¥Â§öÁªÜËäÇÔºåËØ∑ÂèÇÈòÖ [È´òÁ∫ß RAG](advanced_rag) ÁöÑ notebook„ÄÇ\n",
        "\n",
        "Ê≠£Â¶ÇÂú®‰∏ãÈù¢ÁöÑÂõæË°®‰∏≠ÊâÄÁúãÂà∞ÁöÑÔºå‰∏Ä‰∫õË∞ÉÊï¥Âπ∂Ê≤°ÊúâÂ∏¶Êù•‰ªª‰ΩïÊîπÂñÑÔºåËÄåÊúâ‰∫õÂàôÂ∏¶Êù•‰∫ÜÂ∑®Â§ßÁöÑÊÄßËÉΩÊèêÂçá„ÄÇ\n",
        "\n",
        "‚û°Ô∏è ___ÊâÄ‰ª•Ê≤°ÊúâÂçï‰∏ÄÁöÑÂ•ΩÊñπÊ≥ïÔºöÂú®Ë∞ÉÊï¥‰Ω†ÁöÑ RAG Á≥ªÁªüÊó∂ÔºåÂ∫îËØ•Â∞ùËØïÂá†Áßç‰∏çÂêåÁöÑÊñπÂêë„ÄÇ___\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVOxatv99jVT"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "\n",
        "scores = datasets.load_dataset(\"m-ric/rag_scores_cookbook\", split=\"train\")\n",
        "scores = pd.Series(scores[\"score\"], index=scores[\"settings\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqK0Dg2Q9jVT"
      },
      "outputs": [],
      "source": [
        "fig = px.bar(\n",
        "    scores,\n",
        "    color=scores,\n",
        "    labels={\n",
        "        \"value\": \"Accuracy\",\n",
        "        \"settings\": \"Configuration\",\n",
        "    },\n",
        "    color_continuous_scale=\"bluered\",\n",
        ")\n",
        "fig.update_layout(\n",
        "    width=1000,\n",
        "    height=600,\n",
        "    barmode=\"group\",\n",
        "    yaxis_range=[0, 100],\n",
        "    title=\"<b>Accuracy of different RAG configurations</b>\",\n",
        "    xaxis_title=\"RAG settings\",\n",
        "    font=dict(size=15),\n",
        ")\n",
        "fig.layout.yaxis.ticksuffix = \"%\"\n",
        "fig.update_coloraxes(showscale=False)\n",
        "fig.update_traces(texttemplate=\"%{y:.1f}\", textposition=\"outside\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPUOMWGk9jVT"
      },
      "source": [
        "<img src=\"https://huggingface.co/datasets/huggingface/cookbook-images/resolve/main/RAG_settings_accuracy.png\" height=\"500\" width=\"800\">\n",
        "\n",
        "Â¶Ç‰∏äÂõæÊâÄÁ§∫ÔºåËøô‰∫õË∞ÉÊï¥ÂØπÊÄßËÉΩÁöÑÂΩ±ÂìçÂêÑ‰∏çÁõ∏Âêå„ÄÇÂ∞§ÂÖ∂ÊòØË∞ÉÊï¥ÁâáÊÆµÂ§ßÂ∞èÔºåÊó¢ÁÆÄÂçïÂèàÈùûÂ∏∏ÊúâÂΩ±ÂìçÂäõ„ÄÇ\n",
        "\n",
        "‰ΩÜËøôÂè™ÊòØÈíàÂØπÊàë‰ª¨ÁöÑÊÉÖÂÜµÔºö‰Ω†ÁöÑÁªìÊûúÂèØËÉΩÂ§ß‰∏çÁõ∏ÂêåÔºöÁé∞Âú®‰Ω†Â∑≤ÁªèÊúâ‰∫Ü‰∏Ä‰∏™ÂèØÈù†ÁöÑËØÑ‰º∞ÊµÅÊ∞¥Á∫øÔºåÂèØ‰ª•ÂºÄÂßãÊé¢Á¥¢ÂÖ∂‰ªñÈÄâÈ°π‰∫ÜÔºÅüó∫Ô∏è"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "32f463ea32c84e7d9bc1bb76c170f0a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_ae7726e4727e4d6298451aa4559ede5d"
          }
        },
        "715783304b4647ecae49725bea5777f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c53cd547bff4bbc98cc55cf7283edc6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8fddc047c10940ce9d48b13f84001f7c",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "9648a6b9b118409fa5c99419eb2809dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_a885884e492540ec943805bf3f689e8c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8c1bbd364f7540cfa5a9dbc6c7e1df5e",
            "value": ""
          }
        },
        "7744ff3befb347c6a0925eeb29ae534c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_66c16e71676745a8badd398ab053889c",
            "style": "IPY_MODEL_f14ecb1c41fc413d9897e4617ec580ea",
            "value": true
          }
        },
        "cdf11561f3da44ea8ae56f1ceeafca00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_d25a4a1279c94979a2fcbab3456ca82c",
            "style": "IPY_MODEL_b42efb6c58644739850d73005388ed61",
            "tooltip": ""
          }
        },
        "23fbd90a3e9140e9873a9b9f3d44960c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e73bf32b43d4f8cba46e5db5e28f798",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2fdbc55ec3c14f23ab0133107fb90cd9",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "ae7726e4727e4d6298451aa4559ede5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "6c53cd547bff4bbc98cc55cf7283edc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fddc047c10940ce9d48b13f84001f7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a885884e492540ec943805bf3f689e8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c1bbd364f7540cfa5a9dbc6c7e1df5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66c16e71676745a8badd398ab053889c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f14ecb1c41fc413d9897e4617ec580ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d25a4a1279c94979a2fcbab3456ca82c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b42efb6c58644739850d73005388ed61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "0e73bf32b43d4f8cba46e5db5e28f798": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fdbc55ec3c14f23ab0133107fb90cd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7ca55f298eb4414ad50198f09208770": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cf32a3f9ed54041862cec3164ded745",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_81facfe068164284ac22658e79103844",
            "value": "Connecting..."
          }
        },
        "0cf32a3f9ed54041862cec3164ded745": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81facfe068164284ac22658e79103844": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7630c7d2a6df48858b55f6817555b6ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4ddab2a133d494f9adb665380c38a84",
              "IPY_MODEL_e1d521f629db424aafc6b0bf3d319182",
              "IPY_MODEL_701fd33d8bf742b7a36c65faaac7712d"
            ],
            "layout": "IPY_MODEL_930f94e2a23b4b5ca85a1f06ceb7be91"
          }
        },
        "c4ddab2a133d494f9adb665380c38a84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0114ab46748e4714b974d2c685ff2970",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_49d9c8f88fe34322b2033950263b6aca",
            "value": "README.md:‚Äá100%"
          }
        },
        "e1d521f629db424aafc6b0bf3d319182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45122afe4e2240dfa0c76544b9e47444",
            "max": 21,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9d884068cb74b86939e7f42ae23cf48",
            "value": 21
          }
        },
        "701fd33d8bf742b7a36c65faaac7712d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71ea33516c4c46f3af4e213c3bdb12ab",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f1e5616300344e72b5708d0ae8ab737d",
            "value": "‚Äá21.0/21.0‚Äá[00:00&lt;00:00,‚Äá1.70kB/s]"
          }
        },
        "930f94e2a23b4b5ca85a1f06ceb7be91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0114ab46748e4714b974d2c685ff2970": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49d9c8f88fe34322b2033950263b6aca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45122afe4e2240dfa0c76544b9e47444": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9d884068cb74b86939e7f42ae23cf48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71ea33516c4c46f3af4e213c3bdb12ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1e5616300344e72b5708d0ae8ab737d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "074a8622d4e74b038b4a238a367d2d73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa273886c3f14a43a30b9e066a966e82",
              "IPY_MODEL_0a2ade07714b45bcac34ddf05db4b5a8",
              "IPY_MODEL_3351d460f3654eefa5ec55f7cd8deb12"
            ],
            "layout": "IPY_MODEL_d7bdbc4956294556b795130b1ccf02fb"
          }
        },
        "fa273886c3f14a43a30b9e066a966e82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f826c0c5c1a4b56be93d92ba19142f9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0feb654359ee42a5a2eb0fcea9c8e296",
            "value": "huggingface_doc.csv:‚Äá100%"
          }
        },
        "0a2ade07714b45bcac34ddf05db4b5a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1773c0e8d24b436baf47d408ae5772bb",
            "max": 21954601,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e34370413bc46ac84c875666b4b4f64",
            "value": 21954601
          }
        },
        "3351d460f3654eefa5ec55f7cd8deb12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c20b85756d740e1963beb54eaa438df",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cd83bc04017141289ae42aac004971b7",
            "value": "‚Äá22.0M/22.0M‚Äá[00:00&lt;00:00,‚Äá22.5MB/s]"
          }
        },
        "d7bdbc4956294556b795130b1ccf02fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f826c0c5c1a4b56be93d92ba19142f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0feb654359ee42a5a2eb0fcea9c8e296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1773c0e8d24b436baf47d408ae5772bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e34370413bc46ac84c875666b4b4f64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c20b85756d740e1963beb54eaa438df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd83bc04017141289ae42aac004971b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c68c2360cc5e4eed9558cddf3cadba83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_71fd308ef03949aebbde84630ffe30fc",
              "IPY_MODEL_1d325c3a97664d65b6150be2c15ff42b",
              "IPY_MODEL_41ca68cc80f147fcb11f59d599c67c03"
            ],
            "layout": "IPY_MODEL_7993e139a0f34b01b7ebac0a495e1f97"
          }
        },
        "71fd308ef03949aebbde84630ffe30fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b95b460242a45a985de2f88ccb82b21",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f43535d75d3f440ba2221b3ef91d1a6f",
            "value": "Generating‚Äátrain‚Äásplit:‚Äá100%"
          }
        },
        "1d325c3a97664d65b6150be2c15ff42b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b526892b309478e94309f737961b53c",
            "max": 2647,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ba6812e6fda455087d14dd3266bb69e",
            "value": 2647
          }
        },
        "41ca68cc80f147fcb11f59d599c67c03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99deb331d21748bb9ea0960213356528",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_eaa6853bf2ea4b78a2ae9d12647b1909",
            "value": "‚Äá2647/2647‚Äá[00:00&lt;00:00,‚Äá4833.05‚Äáexamples/s]"
          }
        },
        "7993e139a0f34b01b7ebac0a495e1f97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b95b460242a45a985de2f88ccb82b21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f43535d75d3f440ba2221b3ef91d1a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b526892b309478e94309f737961b53c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ba6812e6fda455087d14dd3266bb69e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "99deb331d21748bb9ea0960213356528": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaa6853bf2ea4b78a2ae9d12647b1909": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b7c62a723914de9a28f759ad3e868b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd6e131ae5c440c1bb153c7ae1ae6371",
              "IPY_MODEL_6cc4b010047b4258ba6d152da6d7c76b",
              "IPY_MODEL_20f32624d169465186273bbb2edb7dd4"
            ],
            "layout": "IPY_MODEL_87ed8949d45b40dbb7fadb4fe9e64952"
          }
        },
        "fd6e131ae5c440c1bb153c7ae1ae6371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ed7c849df634e80a42ccbe4f09fa1a0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9eefca8c10b140a6a04c0cc8cc6ec712",
            "value": "100%"
          }
        },
        "6cc4b010047b4258ba6d152da6d7c76b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ce7628b5bb54a9b9c15ba4f96336307",
            "max": 2647,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_44308eae38244f00ab63b43c9d226286",
            "value": 2647
          }
        },
        "20f32624d169465186273bbb2edb7dd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e9c358c2ea14089bd0418fe530d0c01",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f0d07659f56c40c6b71f64222cce9779",
            "value": "‚Äá2647/2647‚Äá[00:00&lt;00:00,‚Äá16266.56it/s]"
          }
        },
        "87ed8949d45b40dbb7fadb4fe9e64952": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ed7c849df634e80a42ccbe4f09fa1a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9eefca8c10b140a6a04c0cc8cc6ec712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ce7628b5bb54a9b9c15ba4f96336307": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44308eae38244f00ab63b43c9d226286": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e9c358c2ea14089bd0418fe530d0c01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0d07659f56c40c6b71f64222cce9779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}